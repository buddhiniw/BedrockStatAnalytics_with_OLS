---
title: "Elastic Net Regression Analysis Report"
author: "Bedrock Analytics"
output: pdf_document 

params:
  dat_data: NA
---
<style type="text/css">

h1.title {
  font-size: 24px;
  font-weight: normal;
}
h3 {
  font-weight:normal;
}
.reveal section img { 
  background:none; 
  border:none; 
  box-shadow:none; 
  }
</style>

```{r include=FALSE}
knitr::opts_chunk$set(comment = NA)
```
### Raw Data Summary
```{r ,echo=F}
dat <- params$dat_data
library(caret)
library(knitr)
library(elasticnet)
library(glmnet) # Package to fit ridge/lasso/elastic net models
library(DMwR)
library(boot) # Package to do bootstrap error estimates

#dat <- read.csv(file='\data\Church_mod.csv')
knitr::kable(dat)

```


### Descriptive Summary Statistics
```{r,echo=F}
# The `params` object is available in the document.
statistics_table <- summary(dat)
statistics_table
#statistics_table <- statistics_table[-c(2,5),]
#statistics_table
```


```{r,echo=F}
dataIn <- dat
indx <- sapply(dataIn, is.factor)
dataIn[indx] <- lapply(dataIn[indx], function(x) as.numeric(x))
dataIn.x <- dataIn[,-1]
cat.vars <- apply(dataIn.x,2,function(x) { all(x %in% 0:1) })
dataIn.continuous <- dataIn.x[!cat.vars]
dataIn.catrgorical <- dataIn.x[cat.vars]
dataIn.continuous.scaled <-scale(dataIn.continuous,center=TRUE, scale=TRUE)
x.scaled <- cbind(as.data.frame(dataIn.continuous.scaled),dataIn.catrgorical)
dataIn.y <- dataIn[1:(nrow(dataIn)-1),1,drop=FALSE]
dataIn.y.scaled <- scale(dataIn.y,center=TRUE, scale=TRUE)
y.scaled <- as.data.frame(dataIn.y.scaled)
x <- as.matrix(x.scaled[1:(nrow(x.scaled)-1),])
y <- as.matrix(y.scaled)
dataIn.scaled.test <- x.scaled[nrow(x.scaled),]
x.test <-as.matrix(dataIn.scaled.test)
```

### Correlations Between Predictors
```{r,echo=F}
corrplot::corrplot(cov(as.matrix(x.scaled)),method = "number")
```

```{r,echo=F}
lambda.grid <- c(0,0.01,0.1,1,10,100)
#lambda.grid <- seq(0,10,by = 1)
s.grid <- seq(0,1,by=0.05)
train.control = trainControl(method = "LOOCV")
search.grid <- expand.grid(.fraction = s.grid, .lambda = lambda.grid)
dataIn.scaled <- cbind(y,x)
dataIn.scaled <- na.omit(dataIn.scaled)
set.seed(42)

train.enet = train(
  x.scaled[1:(nrow(x.scaled)-1),], y.scaled[[1]],
  method = "enet",
  metric = "RMSE",
  tuneGrid = search.grid,
  normalize = FALSE,
  intercept = FALSE,
  trControl = train.control
)
```

### Tuning Parmenter Selection Using Leave-One-Out Cross Validation
```{r,echo=F}
plot(train.enet,xlab="Fraction of L1-norm(s)")
```


```{r,echo=F}


best.fraction <- train.enet$bestTune$fraction
best.lambda <- train.enet$bestTune$lambda
best = which(rownames(train.enet$results) == rownames(train.enet$bestTune))
best.result = train.enet$results[best, ]
rownames(best.result) = NULL
prediction.error <- best.result$RMSE
prediction.rsquared <-best.result$Rsquared
final.enet.model <- train.enet$finalModel
beta.hat.enet.scaled <- predict.enet(final.enet.model,
    s=best.fraction,
    type="coefficient",
    mode="fraction")
y.hat.enet.scaled <- predict.enet(final.enet.model,
    as.data.frame(x.test),
    s=best.fraction,
    type="fit",
    mode="fraction")
y.hat.enet.unscaled <- unscale(y.hat.enet.scaled$fit,dataIn.y.scaled)

```
### Variable Importance
```{r, warning=F,echo=F}
plot(varImp(train.enet))
```

```{r,echo=F}
data <- as.matrix(beta.hat.enet.scaled$coefficients)
data <- formatC(data, digits = 6, format = "f", flag = "0")
k <- row.names(data)
data <- data.frame(data)
#data <- cbind(Row.Names= row.names(data),data)
colnames(data)<-c('Coefficient')

```
### Standardized Model Coefficients
```{r,echo=F}
s_m_c <- knitr::kable(data)
s_m_c
```

```{r,echo=F}
data <- as.matrix(cbind(y.hat.enet.unscaled,prediction.error,prediction.rsquared))
data <- formatC(data, digits = 3, format = "f", flag = "0")
k <- row.names(data)
data <- data.frame(data)
data <- cbind(Row.Names= row.names(data),data)
colnames(data)<-c("","Predicted Value", "Prediction Error", "R2")
```

### Model Prediction
```{r,echo=F}
m_p <- knitr::kable(data)
m_p
```